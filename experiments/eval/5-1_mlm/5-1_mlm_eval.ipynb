{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"TRANSFORMERS_CACHE\"] = \"/network/scratch/m/mirceara/.cache/huggingface/transformers\"\n",
    "os.environ[\"HF_DATASETS_CACHE\"] = \"/network/scratch/m/mirceara/.cache/huggingface/datasets\"\n",
    "os.environ[\"BALAUR_CACHE\"] = \"/network/scratch/m/mirceara/.cache/balaur\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"/home/mila/m/mirceara/balaur/experiments/pretrain/\")\n",
    "from run_bort import MlmModel, MlmModelConfig, MlmWnreDataModule, MlmWnreDataModuleConfig, WNRE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "import transformers as tr\n",
    "from pytorch_lightning import seed_everything"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EvalModel:\n",
    "    @classmethod\n",
    "    def load_bort(cls, ckpt_path: Path, device: str = 'cuda', **kwargs):\n",
    "        em = cls()\n",
    "        ckpt_path = str(ckpt_path.absolute())\n",
    "        ckpt = torch.load(ckpt_path)\n",
    "        config = MlmModelConfig(**kwargs)\n",
    "        config.__dict__.update(ckpt['hyper_parameters'])\n",
    "        em.device = torch.device(device)\n",
    "        em.model_name = ckpt_path\n",
    "        em.model = MlmModel(config).to(em.device)\n",
    "        em.model.load_state_dict(ckpt['state_dict'])\n",
    "        em.step = ckpt['global_step']\n",
    "        em.mask_id = em.model.bort_config.mask_token_id\n",
    "        return em\n",
    "        \n",
    "    @classmethod\n",
    "    def load_hf(cls, model_name: str = 'bert-base-uncased', device: str = 'cuda'):\n",
    "        em = cls()\n",
    "        em.model_name = model_name\n",
    "        em.device = torch.device(device)\n",
    "        em.model = tr.AutoModelForMaskedLM.from_pretrained(model_name).to(em.device)\n",
    "        em.step = 0\n",
    "        em.mask_id = tr.AutoTokenizer.from_pretrained(model_name).mask_token_id\n",
    "        return em\n",
    "    \n",
    "    @torch.inference_mode()\n",
    "    def run_eval_batch(self, batch):\n",
    "        batch = dict(\n",
    "            input_ids=batch['input_ids'].to(self.device),\n",
    "            labels=batch['labels'].to(self.device),\n",
    "        )\n",
    "        if type(self.model) == MlmModel:\n",
    "            src = self.model(batch)\n",
    "            mask_unmasked = batch['input_ids'].view(-1) == self.mask_id\n",
    "            mlm_src = src.view(-1, src.shape[-1])[mask_unmasked]\n",
    "            labels = batch['labels'].view(-1)[mask_unmasked]\n",
    "            logits = self.model.head(mlm_src)\n",
    "            loss = F.cross_entropy(logits, labels)\n",
    "            mlm_loss = loss.item()\n",
    "            mrr = self.compute_mrr(logits, labels)\n",
    "        \n",
    "        else:\n",
    "            out = self.model(**batch)\n",
    "            mlm_loss = out.loss.item()\n",
    "            mask_unmasked = batch['input_ids'].view(-1) == self.mask_id\n",
    "            logits = out.logits\n",
    "            logits = logits.view(-1, logits.shape[-1])[mask_unmasked]\n",
    "            labels = batch['labels'].view(-1)[mask_unmasked]\n",
    "            mrr = self.compute_mrr(logits, labels)\n",
    "            \n",
    "        return mlm_loss, mrr\n",
    "        \n",
    "    @torch.inference_mode()\n",
    "    def compute_mrr(self, logits, labels):\n",
    "        assert len(labels.shape) == 1 and len(logits.shape) == 2, \"logits and labels must be flattened\"\n",
    "        assert labels.shape[0] == logits.shape[0], \"logits must be subsampled to match number of labels\"\n",
    "        target_logits = torch.gather(logits, -1, labels.unsqueeze(-1))\n",
    "        ranks = (logits >= target_logits).sum(dim=-1)\n",
    "        mrr = (1 / ranks).mean().item()\n",
    "        return mrr\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BSZ = 512\n",
    "dc = MlmWnreDataModuleConfig(\n",
    "    dataset_name='wikibooks',\n",
    "    tokenizer='roberta-base',\n",
    "    wnre=True,\n",
    "    per_device_bsz=BSZ,\n",
    "    num_dataloader_workers=1,\n",
    "    complete_docs=True,\n",
    ")\n",
    "dm = MlmWnreDataModule(dc)\n",
    "dm.prepare_data()\n",
    "dm.setup()\n",
    "vdl = dm.val_dataloader()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MLM Only performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 42\n",
    "MAX_STEP = 25_000\n",
    "\n",
    "\n",
    "MODEL_NAME = \"mlm_only\"\n",
    "ckpt_dir = f\"/home/mila/m/mirceara/scratch/.cache/balaur/runs/{MODEL_NAME}/balaur/{MODEL_NAME}/checkpoints/\"\n",
    "dm.config.wnre_only_mask = False\n",
    "seed_everything(seed=SEED)\n",
    "vdl = dm.val_dataloader()\n",
    "mlm_dir = Path(ckpt_dir).parent / \"mlm_eval\"\n",
    "mlm_dir.mkdir(exist_ok=True)\n",
    "for ckpt in sorted(Path(ckpt_dir).glob(\"*step=*.ckpt\"), key=os.path.getmtime):\n",
    "    step = int(ckpt.name.split(\"step=\")[1].split(\".\")[0])\n",
    "    print(ckpt)\n",
    "    model = EvalModel.load_bort(ckpt)\n",
    "    step = model.step\n",
    "    losses = []\n",
    "    mrrs = []\n",
    "    for batch in tqdm(vdl):\n",
    "        with torch.amp.autocast(\"cuda\"):\n",
    "            mlm_loss, mrr = model.run_eval_batch(batch)\n",
    "        losses.append(mlm_loss)\n",
    "        mrrs.append(mrr)\n",
    "    print(np.mean(losses))\n",
    "    (mlm_dir / f\"mlm_{step}\").write_text(json.dumps(losses))\n",
    "    (mlm_dir / f\"mrr_{step}\").write_text(json.dumps(mrrs))\n",
    "    del model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MLM+WNRE performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 42\n",
    "MAX_STEP = 25_000\n",
    "\n",
    "\n",
    "MODEL_NAME = \"mlm_wnre\"\n",
    "ckpt_dir = f\"/home/mila/m/mirceara/scratch/.cache/balaur/runs/{MODEL_NAME}/balaur/{MODEL_NAME}/checkpoints/\"\n",
    "dm.config.wnre_only_mask = False\n",
    "seed_everything(seed=SEED)\n",
    "vdl = dm.val_dataloader()\n",
    "mlm_dir = Path(ckpt_dir).parent / \"mlm_eval\"\n",
    "mlm_dir.mkdir(exist_ok=True)\n",
    "for ckpt in sorted(Path(ckpt_dir).glob(\"*step=*.ckpt\"), key=os.path.getmtime):\n",
    "    step = int(ckpt.name.split(\"step=\")[1].split(\".\")[0])\n",
    "    print(ckpt)\n",
    "    model = EvalModel.load_bort(ckpt, wnre_factor=0.75)\n",
    "    step = model.step\n",
    "    losses = []\n",
    "    mrrs = []\n",
    "    for batch in tqdm(vdl):\n",
    "        with torch.amp.autocast(\"cuda\"):\n",
    "            mlm_loss, mrr = model.run_eval_batch(batch)\n",
    "        losses.append(mlm_loss)\n",
    "        mrrs.append(mrr)\n",
    "    print(np.mean(losses))\n",
    "    (mlm_dir / f\"mlm_{step}\").write_text(json.dumps(losses))\n",
    "    (mlm_dir / f\"mrr_{step}\").write_text(json.dumps(mrrs))\n",
    "    del model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb\n",
    "import plotly.graph_objects as go\n",
    "import plotly.io as pio\n",
    "from IPython.display import display, HTML\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def errorband_trace(x, y, yhi, ylo, legend: str, rgb='0,100,80', add_errorband: bool = True):\n",
    "    trace = [\n",
    "        go.Scatter(\n",
    "            name=legend,\n",
    "            x=x,\n",
    "            y=y,\n",
    "            line=dict(color=f'rgb({rgb})'),\n",
    "            mode='lines'\n",
    "        ),\n",
    "    ]\n",
    "    if add_errorband:\n",
    "        trace.append(go.Scatter(\n",
    "            x=x+x[::-1], # x, then x reversed\n",
    "            y=yhi+ylo[::-1], # upper, then lower reversed\n",
    "            fill='toself',\n",
    "            fillcolor=f'rgba({rgb},0.2)',\n",
    "            line=dict(color='rgba(255,255,255,0)'),\n",
    "            hoverinfo=\"skip\",\n",
    "            showlegend=False\n",
    "        ))\n",
    "    return trace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_step(p: Path):\n",
    "    return int(p.name.split(\"_\")[-1])\n",
    "\n",
    "def get_mrr_mean_std(d):\n",
    "    steps = []\n",
    "    mrr_avg = []\n",
    "    mrr_hi = []\n",
    "    mrr_lo = []\n",
    "    for f in sorted(Path(d).glob(\"mrr_*\"), key=get_step):\n",
    "        mrrs = json.loads(f.read_text())\n",
    "        steps.append(get_step(f))\n",
    "        avg = np.mean(mrrs)\n",
    "        std = np.std(mrrs)\n",
    "        mrr_avg.append(avg)\n",
    "        mrr_hi.append(avg + std)\n",
    "        mrr_lo.append(avg - std)\n",
    "    return steps, mrr_avg, mrr_hi, mrr_lo \n",
    "\n",
    "def get_mlm_mean_std(d):\n",
    "    steps = []\n",
    "    mlm_avg = []\n",
    "    mlm_hi = []\n",
    "    mlm_lo = []\n",
    "    for f in sorted(Path(d).glob(\"mlm_*\"), key=get_step):\n",
    "        mlms = json.loads(f.read_text())\n",
    "        steps.append(get_step(f))\n",
    "        avg = np.mean(mlms)\n",
    "        std = np.std(mlms)\n",
    "        mlm_avg.append(avg)\n",
    "        mlm_hi.append(avg + std)\n",
    "        mlm_lo.append(avg - std)\n",
    "    return steps, mlm_avg, mlm_hi, mlm_lo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL1 = \"mlm_wnre\"\n",
    "DIR1 = f\"/home/mila/m/mirceara/scratch/.cache/balaur/runs/{MODEL1}/balaur/{MODEL1}/mlm_eval\"\n",
    "MODEL2 = \"mlm_only\"\n",
    "DIR2 = f\"/home/mila/m/mirceara/scratch/.cache/balaur/runs/{MODEL2}/balaur/{MODEL2}/mlm_eval\"\n",
    "\n",
    "\n",
    "x1, y1, y1_hi, y1_lo = get_mlm_mean_std(DIR1)\n",
    "x2, y2, y2_hi, y2_lo = get_mlm_mean_std(DIR2)\n",
    "\n",
    "traces = []\n",
    "traces.extend(\n",
    "    errorband_trace(x1, y1, y1_hi, y1_lo,\"BERT+BALAUR\", '65,105,225', add_errorband=False)\n",
    ")\n",
    "traces.extend(\n",
    "    errorband_trace(x2, y2, y2_hi, y2_lo,\"BERT (OURS)\", '255,127,80', add_errorband=False)\n",
    ")\n",
    "fig = go.Figure(traces)\n",
    "\n",
    "# fig.update_xaxes(type=\"log\")\n",
    "fig.update_yaxes(type=\"log\")\n",
    "\n",
    "fig.update_xaxes(title=\"Training steps\")\n",
    "fig.update_yaxes(title=\"MLM Loss\")\n",
    "fig.update_layout(showlegend=True, template='simple_white')\n",
    "fig.update_layout(legend=dict(yanchor='top', xanchor='right', x=0.99,y=0.99))\n",
    "\n",
    "\n",
    "fig.update_layout(width=500, height=250, \n",
    "                  font_family=\"Serif\", \n",
    "                  font_size=12, \n",
    "                  margin_l=5, margin_t=5, margin_b=5, margin_r=5)\n",
    "\n",
    "fig.update_traces(line=dict(width=1.5))\n",
    "display(HTML(fig.to_html()))\n",
    "pio.write_image(fig, \"eval_mlm_loss.pdf\", width=1.5*300, height=0.75*300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (emnlp2023)",
   "language": "python",
   "name": "emnlp2023"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
